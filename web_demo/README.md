# KrishiSahayak+Gemma: Web Demo

This directory contains the source code for the web-based demonstration of the KrishiSahayak project. It uses a Gradio interface to provide a user-friendly way to interact with the multimodal AI pipeline.

## ğŸŒŸ Features
- Image and audio input for crop diagnosis
- AI-powered diagnosis using the `google/gemma-3n-E2B-it` model with on-the-fly 4-bit quantization
- Retrieval-Augmented Generation (RAG) to improve accuracy when the model is uncertain
- Text-to-speech output in Hindi

## ğŸš€ Setup and Execution

### 1. Prerequisites
- Python 3.8+
- `git`

### 2. Create a Virtual Environment
It is a critical best practice to use a Python virtual environment to avoid conflicts with system-wide packages.

```bash
# Create the virtual environment
python -m venv venv

# Activate the environment
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
# source venv/bin/activate
```

### 3. Install Dependencies
This project separates production dependencies from optional development/monitoring packages.

```bash
# Install the core packages required to run the demo
pip install -r requirements.txt

# (Optional) To install tools for monitoring and advanced deployment:
pip install -r requirements-dev.txt
```

### 4. Run the Application
```bash
# Launch the Gradio web server
python app.py
```

The application will start, and you can access it through the local URL provided in your terminal (e.g., http://127.0.0.1:7860).

## ğŸ“ Project Structure

```
web_demo/
â”œâ”€â”€ app.py                # Main application entry point
â”œâ”€â”€ requirements.txt      # Core production dependencies
â”œâ”€â”€ requirements-dev.txt  # Optional development & monitoring dependencies
â””â”€â”€ src/
    â”œâ”€â”€ api/              # API endpoints and routes
    â”‚   â””â”€â”€ routes.py
    â”œâ”€â”€ pipeline/         # Core AI processing pipeline
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ inference.py  # Model loading and inference logic
    â”‚   â””â”€â”€ uncertainty.py # Uncertainty quantification
    â”œâ”€â”€ rag/              # Retrieval-Augmented Generation
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ search.py     # Semantic search implementation
    â”‚   â”œâ”€â”€ monitoring.py # RAG monitoring utilities
    â”‚   â””â”€â”€ performance_monitor.py # Performance tracking
    â””â”€â”€ utils/            # Utility functions
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ audio_processing.py  # Audio handling utilities
        â””â”€â”€ cache_utils.py      # Caching mechanisms
```

## ğŸ¤– Model Information

This demo uses the `google/gemma-3n-E2B-it` model with on-the-fly quantization via the BitsAndBytes library. This is distinct from the pre-quantized `.gguf` asset used by the final Android application.

## ğŸ“ Notes
- The web demo requires an internet connection to download the model weights on first run
- For production deployment, consider using a GPU-accelerated server for better performance
- All sensitive configurations should be managed through environment variables

## ğŸ“„ License
This project is licensed under the MIT License - see the [LICENSE](../LICENSE) file for details.
