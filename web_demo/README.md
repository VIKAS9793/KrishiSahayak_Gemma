# KrishiSahayak+Gemma: Development Tools

> **Development Use Only**: This directory contains development and testing tools for the KrishiSahayak project. These tools are provided for development and testing purposes only and are not part of the production mobile application.

For the project's mission and technical details, please refer to the main documentation in the [docs](../docs/) directory.

## Purpose
- Test and validate the AI pipeline
- Demonstrate core functionality to stakeholders
- Facilitate development and debugging
- Validate model performance

For detailed technical architecture and implementation, see the [Technical Report](../docs/TECHNICAL_REPORT.md).

## ğŸŒŸ Features
- Image and audio input for crop diagnosis
- AI-powered diagnosis using Gemma 3B model
- Retrieval-Augmented Generation (RAG) for accurate responses
- Multilingual text-to-speech support

## ğŸ“¸ Web Demo Interface

The web demo provides a user-friendly interface for testing and demonstrating the core functionality of KrishiSahayak+Gemma. Here's a quick tour of the interface:

![Web Demo Home](../docs/images/web%20demo_1.png)
*Figure 1: Main interface with image upload and audio input options*

![Web Demo Diagnosis](images/web%20demo_2.png)
*Figure 2: Real-time diagnosis with RAG support*

![Web Demo Results](images/web%20demo_3.png)
*Figure 3: Detailed diagnosis results with confidence scores*

![Web Demo Audio](images/web%20demo_4.png)
*Figure 4: Audio input and transcription interface*

![Web Demo Multilingual](images/web%20demo_5.png)
*Figure 5: Multilingual support and text-to-speech options*

## ğŸš€ Quick Start

For detailed setup and deployment instructions, including system requirements and troubleshooting, see the [Deployment Guide](DEPLOYMENT_GUIDE.md).

### Basic Commands
```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
python app.py
```

## ğŸ“š Documentation
- [Deployment Guide](DEPLOYMENT_GUIDE.md) - Complete setup and troubleshooting

## ğŸ“ Project Structure

```
web_demo/
â”œâ”€â”€ app.py                # Main application entry point
â”œâ”€â”€ requirements.txt      # Core production dependencies
â”œâ”€â”€ requirements-dev.txt  # Optional development & monitoring dependencies
â””â”€â”€ src/
    â”œâ”€â”€ api/              # API endpoints and routes
    â”‚   â””â”€â”€ routes.py
    â”œâ”€â”€ pipeline/         # Core AI processing pipeline
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ inference.py  # Model loading and inference logic
    â”‚   â””â”€â”€ uncertainty.py # Uncertainty quantification
    â”œâ”€â”€ rag/              # Retrieval-Augmented Generation
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ search.py     # Semantic search implementation
    â”‚   â”œâ”€â”€ monitoring.py # RAG monitoring utilities
    â”‚   â””â”€â”€ performance_monitor.py # Performance tracking
    â””â”€â”€ utils/            # Utility functions
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ audio_processing.py  # Audio handling utilities
        â””â”€â”€ cache_utils.py      # Caching mechanisms
```

## ğŸ¤– Model Information

For detailed model specifications, see the [Model Card](../docs/model_card.md).

## ğŸ“ Notes
- These tools require an internet connection to download model weights on first run
- For production deployment, consider using a GPU-accelerated server for better performance
- All sensitive configurations should be managed through environment variables

## ğŸ“„ License
This project is licensed under the MIT License - see the [LICENSE](../LICENSE) file for details.
